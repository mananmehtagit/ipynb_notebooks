{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyuDi+T7YZVA+rN1L2Blor",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mananmehtagit/ipynb_notebooks/blob/main/LLM_With_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up a coding environment locally, make sure that you have a functional Python environment (e.g., Python >3.7) and install the following three Python libraries\n",
        "Install Streamlit\n",
        "Install Langchain for Google Gemini AI"
      ],
      "metadata": {
        "id": "HJh3aZvLCdUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit langchain_google_genai\n",
        "\n",
        "\n",
        "#!pip install -q \"google-generativeai>=0.7.2\""
      ],
      "metadata": {
        "id": "sYTCZoiOCgRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Google API Key"
      ],
      "metadata": {
        "id": "OLKo0xVID7ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import PIL.Image\n",
        "from IPython.display import display, Image, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "import json\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY') #get API key from secret\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "HjTqWTo_D-DW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the Integration Code\n"
      ],
      "metadata": {
        "id": "OwfzlvtnEgUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Load the Google API key from environment variables\n",
        "# GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# Initialize the Gemini model\n",
        "llm4 = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key= userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# Define your query\n",
        "text = \"What is the capital of the USA?\"\n",
        "\n",
        "# Get the response from the model\n",
        "response = llm4.predict(text)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGOWH7bREhN0",
        "outputId": "a7d8c61a-708f-42d3-ec32-ac784adf65f1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Washington, D.C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fuser -k 5000/tcp #stop all programs running on port 5000 in your Colab environment"
      ],
      "metadata": {
        "id": "V15yDLy-Rp9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: modify this, add api routes that takes query and run predict method and return output as reponse, create html page, serve over api that execute this api and display response in return serve traffic over ngrok\n",
        "\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import PIL.Image\n",
        "from IPython.display import display, Image, HTML\n",
        "import ipywidgets as widgets\n",
        "import json\n",
        "from typing_extensions import TypedDict\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# Set up a coding environment locally, make sure that you have a functional Python environment (e.g., Python >3.7) and install the following three Python libraries\n",
        "# Install Streamlit\n",
        "# Install Langchain for Google Gemini AI\n",
        "!pip install streamlit langchain_google_genai pyngrok\n",
        "\n",
        "#!pip install -q \"google-generativeai>=0.7.2\"\n",
        "# Get Google API Key\n",
        "\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY') #get API key from secret\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "# Write the Integration Code\n",
        "#\n",
        "\n",
        "# Load the Google API key from environment variables\n",
        "# GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# Initialize the Gemini model\n",
        "llm4 = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key= userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/predict', methods=['GET'])\n",
        "def predict():\n",
        "  query = request.args.get('query')\n",
        "  if not query:\n",
        "    return jsonify({'error': 'Query parameter is missing'}), 400\n",
        "  try:\n",
        "    response = llm4.predict(query)\n",
        "    return jsonify({'response': response})\n",
        "  except Exception as e:\n",
        "    return jsonify({'error': str(e)}), 500\n",
        "\n",
        "html_content = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<title>Langchain<>Gemini API</title>\n",
        "</head>\n",
        "<body>\n",
        "<h1>Gemini API</h1>\n",
        "<form action=\"/predict\" method=\"get\">\n",
        "  <label for=\"query\">Enter your query:</label><br>\n",
        "  <input type=\"text\" id=\"query\" name=\"query\"><br><br>\n",
        "  <input type=\"submit\" value=\"Submit\">\n",
        "</form>\n",
        "<div id=\"response\"></div>\n",
        "\n",
        "<script>\n",
        "  const form = document.querySelector('form');\n",
        "  const responseDiv = document.getElementById('response');\n",
        "\n",
        "  form.addEventListener('submit', async (event) => {\n",
        "    event.preventDefault();\n",
        "    const formData = new FormData(form);\n",
        "    const query = formData.get('query');\n",
        "\n",
        "    try {\n",
        "      const response = await fetch(`/predict?query=${query}`);\n",
        "      const data = await response.json();\n",
        "\n",
        "      if (data.response) {\n",
        "        responseDiv.innerHTML = `<p>Response: ${data.response}</p>`;\n",
        "      } else if (data.error) {\n",
        "        responseDiv.innerHTML = `<p>Error: ${data.error}</p>`;\n",
        "      }\n",
        "    } catch (error) {\n",
        "      responseDiv.innerHTML = `<p>Error: ${error}</p>`;\n",
        "    }\n",
        "  });\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "  return html_content\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  # Start ngrok\n",
        "  ngrok.set_auth_token(userdata.get('NGROK_AUTH_TOKEN')) # Replace with your ngrok auth token\n",
        "  public_url = ngrok.connect(5000).public_url\n",
        "  print(f\" * ngrok tunnel \\\"{public_url}\\\"\")\n",
        "\n",
        "  # Run the Flask app\n",
        "  app.run(port=5000)"
      ],
      "metadata": {
        "id": "s66rdBHdNdHc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}